{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bigData_hw3_q1.ipynb","provenance":[],"collapsed_sections":["h9BShh5J7IRb","AmCekMR4t_Xg","Ka6k1HjfFavT","oEQJOu--KtOm"],"authorship_tag":"ABX9TyOLf6SnanAgEV2zP5MXxMpk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7S5fJX2JEBKf"},"source":["# گام اول"]},{"cell_type":"markdown","metadata":{"id":"h9BShh5J7IRb"},"source":["### آماده‌سازی کولب"]},{"cell_type":"code","metadata":{"id":"7AVZrJVxRJx4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623590151230,"user_tz":-270,"elapsed":32109,"user":{"displayName":"Masoud Rahimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieDDlS-d2ODFVfxEtXOhRs86VSGb1fRf3sOFvww=s64","userId":"03226949582558521016"}},"outputId":"23229f3a-de11-4866-f096-f818baf1177a"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M-588AkAVj-e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623590151231,"user_tz":-270,"elapsed":20,"user":{"displayName":"Masoud Rahimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieDDlS-d2ODFVfxEtXOhRs86VSGb1fRf3sOFvww=s64","userId":"03226949582558521016"}},"outputId":"bbd5aa0d-7a2b-4856-e626-f56aadf56241"},"source":["# !rm -r spark*\n","!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["gdrive\tsample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J4B86OZ469Ev","executionInfo":{"status":"ok","timestamp":1623590182277,"user_tz":-270,"elapsed":31055,"user":{"displayName":"Masoud Rahimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieDDlS-d2ODFVfxEtXOhRs86VSGb1fRf3sOFvww=s64","userId":"03226949582558521016"}}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n","!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n","!pip install -q findspark"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"72AxxcP07Yb_","executionInfo":{"status":"ok","timestamp":1623590182278,"user_tz":-270,"elapsed":15,"user":{"displayName":"Masoud Rahimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieDDlS-d2ODFVfxEtXOhRs86VSGb1fRf3sOFvww=s64","userId":"03226949582558521016"}}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ct8rg-Uu89ob","colab":{"base_uri":"https://localhost:8080/","height":214},"executionInfo":{"status":"ok","timestamp":1623590188279,"user_tz":-270,"elapsed":6015,"user":{"displayName":"Masoud Rahimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieDDlS-d2ODFVfxEtXOhRs86VSGb1fRf3sOFvww=s64","userId":"03226949582558521016"}},"outputId":"23a34d5f-226c-4564-cff5-923757ddf14b"},"source":["import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n","spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n","sc = spark.sparkContext\n","spark"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://ffa5dc2fc38e:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f38bea0f5d0>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"AmCekMR4t_Xg"},"source":["## بخش اول"]},{"cell_type":"markdown","metadata":{"id":"sBzRXoGkCEt1"},"source":["پس از راه ‌اندازی کولب جهت کار با اسپارک، داده‌ها را از طریق گوگل درایو لود می‌کنیم. سپس به کمک توابعی که در کد قابل مشاهده است، جملات را به کلمات تکی جدا می‌کنیم. و در مرحله‌ی بعدی، هر کلکه‌ای در فایل مشاهده می‌کنیم را به دوتایی (کلمه،۱) تبدیل می‌کنیم. در نهایت با شمارش اسن دوتایی های مشابه، تعداد  تکرار هر کلمه را در متن می‌یابیم. قسمتی از خروجی در نتیجه کد سلول بعدی قابل مشاهده است. از آنجایی که نمایش کامل خروجی در اینجا میسر نبود، نتیجه را یک فایل تکست ذخیره کرده‌ام و ضمیمه شده است"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"td7IaKDygQKx","executionInfo":{"status":"ok","timestamp":1622463971725,"user_tz":-270,"elapsed":1608,"user":{"displayName":"Masoud Rahimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieDDlS-d2ODFVfxEtXOhRs86VSGb1fRf3sOFvww=s64","userId":"03226949582558521016"}},"outputId":"907457da-0bcd-4ce0-958c-585ea37978b4"},"source":["def punctuation_eliminator(word):\n","  import re \n","  x = re.sub(\"[^a-zA-Z]+\", \"\", word)\n","  return x\n","\n","# loading data\n","text = spark.sparkContext.textFile('/content/gdrive/My Drive/bigData_hw3/q1/input.txt')\n","\n","# removing punctuation by using punctuation_eliminator fn.\n","words = text.flatMap(lambda line: line.split(\" \")).map(punctuation_eliminator)\n","\n","# mapping (word, 1): each word give us a (word, 1) \n","maped_words = words.map(lambda word: (word, 1))\n","print('Number of words in input: ', maped_words.count())\n","print('---'*15)\n","\n","### counting distinct word\n","DistinctWordsCount = maped_words.reduceByKey(lambda a,b:a +b)\n","print('Number of distinct words in input: ',DistinctWordsCount.count())\n","print('---'*15)\n","\n","### counting repetition of each word\n","SortedWordsCount = DistinctWordsCount.map(lambda a: (a[1], a[0])).sortByKey(\"desc\")\n","print('sorted words:', SortedWordsCount.top(50))\n","\n","# saving ouput in a textfile as a RDD file but we do NOT use it... because we want all results in one text file. so we use\n","# SortedWordsCount.saveAsTextFile('/content/gdrive/My Drive/bigData_hw3/q1/result_game1_part1.txt')\n","# saving output as a list in a text file in colab\n","SortedWordsCount_list = DistinctWordsCount.map(lambda a: (a[1], a[0])).sortByKey(ascending=False).collect()\n","with open('/content/gdrive/My Drive/bigData_hw3/q1/result_game1_part1.txt', 'w') as writefile:\n","  for element in SortedWordsCount_list:\n","    writefile.write(str(element) + '\\n')\n","\n","print('---'*15)\n","print('Result has been saved in google drive in a text file named \"result_game1_part1.txt\"')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of words in input:  5043\n","---------------------------------------------\n","Number of distinct words in input:  1308\n","---------------------------------------------\n","sorted words: [(312, 'the'), (237, 'and'), (162, 'of'), (152, 'to'), (116, 'in'), (106, 'a'), (76, 'is'), (60, 'that'), (57, 'people'), (52, 'they'), (52, 'it'), (44, 'this'), (44, ''), (41, 'was'), (41, 'I'), (40, 'on'), (39, 'have'), (38, 'with'), (33, 'you'), (33, 'them'), (32, 'are'), (30, 'This'), (29, 'were'), (28, 'all'), (27, 'for'), (25, 'be'), (24, 'up'), (24, 'can'), (24, 'as'), (23, 'time'), (23, 'The'), (21, 'when'), (21, 'what'), (20, 'game'), (20, 'about'), (19, 'which'), (19, 'their'), (19, 'like'), (19, 'from'), (19, 'but'), (18, 'will'), (18, 'who'), (18, 'more'), (18, 'get'), (18, 'because'), (17, 'way'), (17, 'one'), (17, 'has'), (17, 'London'), (16, 'so')]\n","Result has been saved in google drive in a text file named \"result_game1_part1.txt\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ka6k1HjfFavT"},"source":["## بخش دوم"]},{"cell_type":"markdown","metadata":{"id":"0ueLiTcOERTx"},"source":["باری یافتن تعداد کلماتی که با ام انگلیسی شروع می‌شوند از کدی که در سلول بعدی آن را آورده ام استفاده می‌کنیم. بعد از اعمال فیلتر روی حرف اول کلمات، مشاببه قسمت قبل شروع به شمار تعداد تکرار کلمات می‌کنیم. در نهایت خروجی را در یک فایل تکت ذخیره می‌کنیم. خروجی شامل کللماتی که با حرف ام شروع می‌شپند و تعداد تکرار آن‌ها است\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ctYbmoYiGR07"},"source":["we need words that start with \"m\" or \"M\". so, using below code in order to filter on first letter of each word :\n","\n","> words.filter(lambda x: x.startswith('m') or x.startswith('M'))\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"6gQjhtZA3XnP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622463974686,"user_tz":-270,"elapsed":486,"user":{"displayName":"Masoud Rahimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieDDlS-d2ODFVfxEtXOhRs86VSGb1fRf3sOFvww=s64","userId":"03226949582558521016"}},"outputId":"5843c494-5584-4183-d73e-945dbd5501e7"},"source":["# A function in order to remove punctuation\n","def punctuation_eliminator(word):\n","  import re \n","  x = re.sub(\"[^a-zA-Z]+\", \"\", word)\n","  return x\n","\n","# loading data\n","text = spark.sparkContext.textFile('/content/gdrive/My Drive/bigData_hw3/q1/input.txt')\n","\n","### counting all words\n","# removing punctuation by using punctuation_eliminator fn.\n","words = text.flatMap(lambda line: line.split(\" \")).map(punctuation_eliminator)\n","\n","# getting the words that start with M or m:\n","words_starts_with_m = words.filter(lambda x: x.startswith('m') or x.startswith('M'))\n","print(\"Number of words that starst with 'm' or 'M': \", words_starts_with_m.count())\n","print('\\n', '---'*15, '\\n')\n","print(\"some words that starts with 'm' or 'M' :\", '\\n')\n","print(words_starts_with_m.take(100))\n","\n","# saving the output in a text file in colab\n","with open('/content/gdrive/My Drive/bigData_hw3/q1/result_game1_part2.txt', 'w') as writefile:\n","  for element in words_starts_with_m.collect():\n","    writefile.write(str(element) + '\\n')\n","\n","print('Result has been saved in google drive in a text file named \"result_game1_part2.txt\"')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of words that starst with 'm' or 'M':  150\n","\n"," --------------------------------------------- \n","\n","some words that starts with 'm' or 'M' : \n","\n","['make', 'make', 'mastery', 'many', 'me', 'make', 'me', 'me', 'my', 'more', 'minute', 'might', 'me', 'me', 'my', 'moves', 'me', 'my', 'my', 'my', 'make', 'my', 'me', 'me', 'more', 'more', 'members', 'more', 'made', 'much', 'more', 'me', 'make', 'me', 'more', 'me', 'mastering', 'merely', 'method', 'my', 'me', 'money', 'Marjane', 'many', 'many', 'more', 'magical', 'may', 'more', 'material', 'majority', 'Marjane', 'Marjane', 'many', 'more', 'Marjane', 'more', 'meaning', 'monochromatic', 'much', 'more', 'more', 'meant', 'martyred', 'made', 'more', 'Marjane', 'my', 'much', 'more', 'most', 'me', 'Many', 'majority', 'much', 'make', 'much', 'making', 'many', 'Magog', 'myths', 'most', 'major', 'means', 'moving', 'modern', 'most', 'my', 'most', 'many', 'Many', 'made', 'most', 'move', 'many', 'moved', 'moved', 'modern', 'me', 'most']\n","Result has been saved in google drive in a text file named \"result_game1_part2.txt\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oEQJOu--KtOm"},"source":["## بخش سوم"]},{"cell_type":"markdown","metadata":{"id":"TbMvUS7mGzG2"},"source":["ابتدا علايم نگارسی را حذف می‌کنیم، سپس به کمک فیلتر کلماتی که دارای صول ۵ هستند را به مرحله‌ی بعد می‌فرستیم (منظور از کلمات با طول ۵، کلمات ۶ حرفی است). سپس به کمک فیلتر کلماتی که با حروف صدا دار شروع می‌شوند را حذف می‌کنیم. درنهایت با انجام عمل ردیوس تعداد کلمات را می‌شماریم. بخشی از خروجی در نتیجه سلول زیر قابل مشاهده است؛ خروجی کامل در فایل متنی ضمیمه شده است"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvZRWJZAH-OQ","executionInfo":{"status":"ok","timestamp":1622535549669,"user_tz":-270,"elapsed":787,"user":{"displayName":"Masoud Rahimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieDDlS-d2ODFVfxEtXOhRs86VSGb1fRf3sOFvww=s64","userId":"03226949582558521016"}},"outputId":"6821ce71-0f82-4ed9-ad93-337625619e31"},"source":["import re \n","def punctuation_eliminator(word):  # A fn in order to remove punctuation marks.\n","  x = re.sub(\"[^a-zA-Z]+\", \"\", word)\n","  return x\n","\n","def not_vowel_initializer(input_word): # A fn in order to remove words that start with vowel sounds.\n","  if input_word[0] not in 'aeiouAEIOU':\n","    return input_word \n","\n","# loading data\n","text = spark.sparkContext.textFile('/content/gdrive/My Drive/bigData_hw3/q1/input.txt')\n","\n","# removing punctuation by using punctuation_eliminator fn.\n","words = text.flatMap(lambda line: line.split(\" \")).map(punctuation_eliminator)\n","\n","# getting the words with five letter\n","five_letter_words = words.filter(lambda x: len(x) == 5)\n","\n","# removing word that start with vowel sounds\n","not_vowel_initializer_words_five_letter = five_letter_words.filter(not_vowel_initializer)\n","\n","# map-reduce job\n","map_reduced = not_vowel_initializer_words_five_letter.map(lambda word: (word, 1)).reduceByKey(lambda a,b:a +b).map(lambda a: (a[1], a[0])).sortByKey(ascending=False)\n","map_reduced.take(30)\n","\n","# printing\n","print(\"Number of word that contains 5 letters and does not contain a vowel word in first letter: \", not_vowel_initializer_words_five_letter.count())\n","print('---'*15, '\\n')\n","print(\"some words that contains 5 letters and does not contain a vowel word in first letter:\", '\\n')\n","print(map_reduced.take(30), '\\n')\n","\n","# saving the output in a text file in colab\n","with open('/content/gdrive/My Drive/bigData_hw3/q1/result_game1_part3_tuple.txt', 'w') as writefile:\n","  for element in map_reduced.collect():\n","    writefile.write(str(element) + '\\n')\n","print('---'*20, '\\n' 'Result has been saved in google drive in a text file named \"result_game1_part3_tuple.txt\"')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of word that contains 5 letters and does not contain a vowel word in first letter:  487\n","--------------------------------------------- \n","\n","some words that contains 5 letters and does not contain a vowel word in first letter: \n","\n","[(19, 'which'), (19, 'their'), (15, 'games'), (15, 'could'), (14, 'these'), (13, 'style'), (12, 'where'), (12, 'think'), (11, 'there'), (11, 'place'), (10, 'would'), (9, 'great'), (7, 'class'), (7, 'There'), (7, 'being'), (6, 'Buddy'), (6, 'These'), (6, 'lying'), (6, 'times'), (5, 'three'), (5, 'world'), (5, 'first'), (5, 'while'), (5, 'hence'), (5, 'spend'), (4, 'story'), (4, 'point'), (4, 'quite'), (4, 'based'), (4, 'young')] \n","\n","------------------------------------------------------------ \n","Result has been saved in google drive in a text file named \"result_game1_part3_tuple.txt\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IBQOiA_ZZKCU"},"source":["## بخش چهارم"]},{"cell_type":"markdown","metadata":{"id":"uR8LBXd5byOs"},"source":["### a) using part one to extract stop words"]},{"cell_type":"markdown","metadata":{"id":"7kIfqcGyIpt3"},"source":["ابتدا به کمک بخش اول کلماتی که جزء ۱۰٪ کلمات پرتکرار هستندد را می‌یابیم و آن‌ها را به عنوان ایست واژه‌ها در نظر می‌گیریم. برای این منظور دوتایی‌های کلمات و تعداد تکرار آن‌ها را متناسب با تعداد تکرا سورت می‌کنیم و سپس ۱۰٪ ابتدایی لیست سورت شده را به عنوان ایست واژه در نظر می‌گیریم"]},{"cell_type":"code","metadata":{"id":"IT-hjj5LWdRQ"},"source":["def punctuation_eliminator(word):\n","  import re \n","  x = re.sub(\"[^a-zA-Z]+\", \"\", word)\n","  return x\n","\n","# loading data\n","text = spark.sparkContext.textFile('/content/gdrive/My Drive/bigData_hw3/q1/input.txt')\n","\n","### counting all words\n","# removing punctuation by using punctuation_eliminator fn.\n","words = text.flatMap(lambda line: line.split(\" \")).map(punctuation_eliminator)\n","\n","# mapping (word, 1): each word give us a (word, 1) \n","maped_words = words.map(lambda word: (word, 1))\n","\n","### counting distinct word\n","DistinctWordsCount = maped_words.reduceByKey(lambda a,b:a +b)\n","\n","### counting repetition of each word\n","SortedWordsCount = DistinctWordsCount.map(lambda a: (a[1], a[0])).sortByKey(\"desc\")\n","number_of_stopWords = int(SortedWordsCount.count() * 0.1)\n","\n","# finding stop words\n","stopWords_tuple = SortedWordsCount.top(number_of_stopWords)\n","stopWords = [ a[1] for a in stopWords_tuple ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FB9Shj0FfvvX"},"source":["### b) "]},{"cell_type":"markdown","metadata":{"id":"qmUgXDRmJajE"},"source":["سپس فایل ورودی را می‌گیریم. در هر خط ایست واه‌ها و علايم نگارشی را حذف می‌کنیم. در نهایت یک متن همانند متن ورودی را به عنوان خروجی بازمی‌گردانیم. البته در خروجی ایست واه‌ها و علايم نگارشی حذف شده‌اند. توجه داریم که در نتیجه‌ی سلول بعدی مقادیر داخل لیت قرار گرفته اند که صرفا برای تست درستی روش می‌باشد. در نهایت خروجی در فایل متنی ذخیره شده است. فایل نیز ضمیمه شده است"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xHLYv5EMfOGB","executionInfo":{"status":"ok","timestamp":1622532526674,"user_tz":-270,"elapsed":410,"user":{"displayName":"Masoud Rahimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieDDlS-d2ODFVfxEtXOhRs86VSGb1fRf3sOFvww=s64","userId":"03226949582558521016"}},"outputId":"d873680b-e878-4e37-da21-1cbc2ab878b0"},"source":["import re\n","def removing_stop_words_and_punctuation(text):  \n","  '''\n","  this function take a sentence as input.\n","  at first, remove all non alphabet characters.\n","  then, remove all word that are stop word (we use stop words from global variable).\n","  finally, edited sentence is returned\n","  '''\n","  global stopWords\n","\n","  # removing non-alphabet characters\n","  removed_non_alphabet = re.sub(\"[^a-zA-Z]+\", \" \", text)\n","\n","  # putting each word of sentece in list. each word is a list element\n","  list_removed_non_alphabet = removed_non_alphabet.split()\n","\n","  # making a new blank string in order to add words into it. finally, this string will be edited sentence.\n","  edited_text = ''\n","  for word in list_removed_non_alphabet:\n","    if word not in stopWords:\n","      edited_text += word + ' '\n","  return edited_text\n","\n","# loading data\n","text = spark.sparkContext.textFile('/content/gdrive/My Drive/bigData_hw3/q1/input.txt')\n","\n","# take each sentence and edit it (editing refer removing punctuation and stopWords)\n","sentences = text.flatMap(lambda line: line.split(\".\")).map(removing_stop_words_and_punctuation)\n","\n","# testing the method by comparison of input and edited sentece\n","print('testing the method by comparison of some input and edited sentece:')\n","print('input text:')\n","print(text.flatMap(lambda line: line.split(\".\")).take(2))   ## input\n","print('ouput text:')\n","print(sentences.take(2), '\\n')                          ## edited\n","\n","# saving the output in a text file in colab;\n","with open('/content/gdrive/My Drive/bigData_hw3/q1/result_game1_part4.txt', 'w') as writefile:\n","  for element in sentences.collect() :\n","    writefile.write(str(element) )\n","print('---'*20, '\\n', 'Result has been saved in google drive in a text file named \"result_game1_part4.txt\"')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["testing the method by comparison of some input and edited sentece:\n","input text:\n","['Games are a fun way to get people involved and learning in a happy environment and get them to work on concepts and tactics without them knowing it a lot of the time', ' Because of this, these games were perfect in a class on negotiation and persuasion because it loosened people up and allowed them to learn in a fun environment']\n","ouput text:\n","['Games fun involved learning happy environment work concepts tactics without knowing lot ', 'Because perfect negotiation persuasion loosened allowed learn fun environment '] \n","\n","------------------------------------------------------------ \n"," Result has been saved in google drive in a text file named \"result_game1_part4.txt\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HzcvESuKc0Mp"},"source":["## بخش پنجم"]},{"cell_type":"markdown","metadata":{"id":"qaCNHs0QLeoV"},"source":["جهت پیدا کردن دو کلمه‌ای هایی که پشت هم قرار گرفته اند، از کد زیر استفاده می‌کنیم\n","\n","> flatMap(lambda xs: (tuple(x) for x in zip(xs, xs[1:])))\n","\n","سپس همانند مرحله‌های قبلی این دوتایی ها را می‌شماریم. قسمتی از خروجی در نتیجه سلول بعدی نمایش داده شده است و خروجی کامل در فایل متنی ضمیمه شده است"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qF2UlkUicKlI","executionInfo":{"status":"ok","timestamp":1622534572305,"user_tz":-270,"elapsed":803,"user":{"displayName":"Masoud Rahimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhieDDlS-d2ODFVfxEtXOhRs86VSGb1fRf3sOFvww=s64","userId":"03226949582558521016"}},"outputId":"a3ad6fbd-e450-47af-c43e-d5f3a55f48c1"},"source":["import re \n","def punctuation_eliminator(word):  # A fn in order to remove punctuation marks.\n","  x = re.sub(\"[^a-zA-Z]+\", \" \", word)\n","  return x\n","\n","# loading data\n","text = spark.sparkContext.textFile('/content/gdrive/My Drive/bigData_hw3/q1/input.txt')\n","\n","# removing punctuation by using punctuation_eliminator fn.\n","text_no_punctuation = text.map(punctuation_eliminator)\n","\n","# putting bigrams and rep in a tuple\n","bigrams = text_no_punctuation.map(lambda line: line.strip().split(\" \")) \\\n","                   .flatMap(lambda xs: (tuple(x) for x in zip(xs, xs[1:])))\n","\n","# sorting by value; filtering if value is bigger than one.\n","sorted_bigrams = bigrams.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).sortBy(lambda a: a[1], ascending=False).filter(lambda a: a[1]>1)\n","\n","# printing a small sample of result\n","print('some sorted bigrams for sample:', '\\n')\n","print(count_bigrams.take(100), '\\n')\n","\n","# saving the output in a text file in colab\n","with open('/content/gdrive/My Drive/bigData_hw3/q1/result_game1_part5.txt', 'w') as writefile:\n","  for element in sorted_bigrams.collect():\n","    writefile.write(str(element) + '\\n')\n","print('---'*20,'\\n','Result has been saved in google drive in a text file named \"result_game1_part5.txt\"')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["some sorted bigrams for sample: \n","\n","[(('of', 'the'), 56), (('in', 'the'), 48), (('and', 'the'), 15), (('on', 'the'), 12), (('all', 'of'), 12), (('to', 'the'), 11), (('Soho', 'Square'), 11), (('of', 'this'), 10), (('people', 'to'), 10), (('of', 'a'), 10), (('to', 'get'), 9), (('with', 'the'), 9), (('in', 'a'), 9), (('it', 'is'), 9), (('them', 'to'), 8), (('This', 'is'), 8), (('the', 'square'), 8), (('that', 'I'), 7), (('the', 'game'), 7), (('this', 'is'), 7), (('for', 'the'), 7), (('is', 'the'), 7), (('one', 'of'), 7), (('the', 'way'), 7), (('have', 'been'), 7), (('in', 'London'), 7), (('in', 'this'), 6), (('will', 'be'), 6), (('that', 'they'), 6), (('and', 'then'), 6), (('everyone', 'and'), 6), (('have', 'a'), 6), (('is', 'a'), 6), (('it', 'was'), 6), (('as', 'a'), 6), (('gender', 'and'), 6), (('the', 'Romans'), 6), (('get', 'people'), 5), (('the', 'time'), 5), (('of', 'them'), 5), (('Fuck', 'Your'), 5), (('I', 'm'), 5), (('people', 'and'), 5), (('want', 'to'), 5), (('with', 'people'), 5), (('me', 'to'), 5), (('that', 'the'), 5), (('In', 'the'), 5), (('they', 'were'), 5), (('can', 'be'), 5), (('to', 'be'), 5), (('the', 'film'), 5), (('on', 'a'), 5), (('the', 'people'), 5), (('and', 'hence'), 5), (('and', 'not'), 5), (('their', 'time'), 5), (('the', 'games'), 5), (('Your', 'Buddy'), 5), (('some', 'of'), 5), (('at', 'the'), 5), (('to', 'think'), 5), (('you', 'have'), 5), (('is', 'also'), 5), (('I', 'was'), 5), (('they', 'are'), 5), (('way', 'that'), 5), (('and', 'this'), 5), (('the', 'area'), 5), (('of', 'London'), 5), (('because', 'it'), 4), (('on', 'your'), 4), (('and', 'such'), 4), (('of', 'these'), 4), (('and', 'what'), 4), (('what', 'they'), 4), (('tell', 'them'), 4), (('rid', 'of'), 4), (('and', 'I'), 4), (('and', 'all'), 4), (('and', 'they'), 4), (('they', 'had'), 4), (('important', 'to'), 4), (('had', 'to'), 4), (('It', 'is'), 4), (('they', 'can'), 4), (('I', 'want'), 4), (('wanted', 'to'), 4), (('a', 'game'), 4), (('people', 'can'), 4), (('and', 'sexuality'), 4), (('a', 'few'), 4), (('from', 'the'), 4), (('the', 'city'), 4), (('London', 'and'), 4), (('people', 'who'), 4), (('the', 'theatre'), 4), (('spend', 'their'), 4), (('way', 'to'), 4), (('but', 'the'), 4)] \n","\n","------------------------------------------------------------ \n"," Result has been saved in google drive in a text file named \"result_game1_part5.txt\"\n"],"name":"stdout"}]}]}