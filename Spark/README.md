# Spark Project

This project provides hands-on experience working with Apache Spark for big data processing.

## Getting Started

The project is completed using Google Colab notebooks. The required datasets for each part of the project are uploaded with the exercise instructions.

To get started with Spark in Colab, go through this quick tutorial: [Colab and PySpark Tutorial](https://jacobcelestine.com/knowledge_repo/colab_and_pyspark/)

## Exercises

The project contains the following exercises to learn Spark:

### Basics

- Count words and word frequencies in a text file
- Find words starting with 'M'
- Count and filter 5-letter words
- Find stop words and remove them
- Find frequent bigrams

### Log File Analysis

Analyze a server log file to find:

- Number of unique hosts
- Average daily requests per host
- Number of GIF requests
- Top domains by request frequency
- HTTP error frequencies

### DataFrames and SQL

Use Spark DataFrames and Spark SQL to analyze stock market data:

- Most expensive and cheapest stocks
- Highest trading volumes
- Biggest price increases each month
- Biggest price drops overall
- Most days closed

### Graph Analysis

Build a graph from Wikipedia links data and analyze:

- Highest in and out degrees
- Component sizes
- Top pages by in degree

